---
title: Multipath schedulers
abbrev: Multipath schedulers
docname: draft-bla-schedulers-00
date: 2020-01-30
category: exp

ipr: trust200902
area: IRTF
workgroup: ICCRG Working Group
keyword: Internet-Draft

coding: us-ascii
stand_alone: yes
pi: [toc, sortrefs, symrefs]

author:
 -
  ins: O. Bonaventure
  name: Olivier Bonaventure
  organization: UCLouvain
  email: Olivier.Bonaventure@uclouvain.be
 -
  ins: M. Piraux
  name: Maxime Piraux
  organization: UCLouvain
  email: Maxime.Piraux@uclouvain.be
 -
  ins: Q. De Coninck
  name: Quentin De Coninck
  organization: UCLouvain
  email: quentin.deconinck@uclouvain.be
 -
  ins: M. Baerts
  name: Matthieu Baerts
  organization: Tessares
  email: Matthieu.Baerts@tessares.net
 -
  ins: C. Paasch
  name: Christoph Paasch
  organization: Apple
  email: cpaasch@apple.com
 -
  ins: M. Amend
  name: Markus Amend
  organization: Deutsche Telekom
  email: markus.amend@telekom.de

normative:

informative:
  RFC6824:
  RFC2119:
  RFC8174:
  RFC6356:
  RFC6298:
  I-D.tuexen-tsvwg-sctp-multipath:
  I-D.deconinck-quic-multipath:
  I-D.amend-tsvwg-multipath-dccp:
  TS23501:
    author:
      - ins: 3GPP (3rd Generation Partnership Project)
    title: Technical Specification Group Services and System Aspects; System Architecture for the 5G System; Stage 2 (Release 16)
    date: 2019
    target: https://www.3gpp.org/ftp/Specs/archive/23_series/23.501/
  IETFJ16:
    author:
      - ins: O. Bonaventure
      - ins: S. Seo
    title: Multipath TCP Deployment
    seriesinfo: IETF Journal, Fall 2016
  ACMCS14:
    author:
     - ins: C. Paasch
     - ins: S. Ferlin
     - ins: O. Alay
     - ins: O. Bonaventure
    title: Experimental Evaluation of Multipath TCP Schedulers
    seriesinfo: Proceedings of the 2014 ACM SIGCOMM workshop on Capacity sharing workshop
  NSDI12:
    author:
     - ins: C. Raiciu
     - ins: C. Paasch
     - ins: S. Barre
     - ins: A. Ford
     - ins: M. Honda
     - ins: F. Duchene
     - ins: O. Bonaventure
     - ins: M. Handley
    title: How Hard Can It Be? Designing and Implementing a Deployable Multipath TCP
    seriesinfo: 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 12)
  CONEXT15:
    author:
     - ins: B. Hesmans
     - ins: G. Detal
     - ins: S. Barre
     - ins: R. Bauduin
     - ins: O. Bonaventure
    title: SMAPP &#58; Towards Smart Multipath TCP-enabled APPlications
    seriesinfo: CoNEXT '15&#58; Proceedings of the 11th ACM Conference on Emerging Networking Experiments and Technologies
  TODO:
    author:
     - ins: To be provided
    title: Some title
    seriesinfo: somewhere

--- abstract

This document proposes a series of abstract packet schedulers for
multipath transport protocols equipped with a congestion controller.

--- middle


# Introduction  {#intro}

The Internet was designed under the implicit assumption that hosts are
equipped with a single network interface while routers are equipped with several
ones. Under this assumption, an Internet host is usually
identified by the IP address of its network interface.

This assumption does not hold anymore today for two reasons. First,
a growing fraction of the Internet hosts are equipped with several network
interfaces, usually through different datalink networks. These multihomed
hosts are reachable via different IP addresses. Second, a growing
fraction of the hosts that are attached through a single network interface are
dual-stack and are thus reachable over both IPv4 and IPv6.

Several Internet transport protocols have been extended to leverage the
different paths that are exposed on such hosts: Multipath TCP {{RFC6824}}, the
load sharing extensions to SCTP {{I-D.tuexen-tsvwg-sctp-multipath}}, Multipath
DCCP {{I-D.amend-tsvwg-multipath-dccp}} and
Multipath QUIC {{I-D.deconinck-quic-multipath}}. These multipath transport
protocols differ in the way they are organized and exchange control information
and user data. However, they all include algorithms to handle three problems
that any multipath transport protocol needs to solve:

 - Congestion controller
 - Path manager
 - Packet scheduler
 - Packet re-assembly

From a congestion control viewpoint, the main concern for a multipath transport
protocol is that a multipath connection should not be unfair to single-path
transport connections that share a common bottleneck. This problem can be solved
by coupling the congestion windows of the different paths. The solution proposed
in {{RFC6356}} is applicable to any transport protocol. Beside providing fairness,
congestion control can also be a valuable input for different kind of traffic
distribution algorithm within a packet scheduler. Typically metrics like RTT and
available capacity can be derived.

A multipath transport protocol uses different flows during the lifetime of a
connection. The Path Manager contains the logic that regulates the
creation/deletion of these flows. This logic usually depends on the
requirements of the application that uses the multipath transport. Some
applications use multipath in failover situations. In this case, the connection
can use one path and the path manager can create another path when the primary
one fails. An application that wishes to share its load among different paths
can request the path manager to establish different paths in order to
simultaneously use them during the connection. Many path managers have been
proposed in the literature {{CONEXT15}}, but these are outside the scope of this
document.

[comment]: # (OB: It would probably make sense to write such a document on path managers as well; MA: Agree)


The packet scheduler is the generic term for the algorithm that selects the
path that will be used to transmit each packet on a multipath connection. This
logic is obviously only useful when there are at least two active paths for
a given multipath transport connection. A variety of packet schedulers have
been proposed in the literature {{TODO}} and implemented in multipath transport
protocols. Experience with multipath transport protocols shows that the
packet scheduler can have a huge impact on the performance achieved by
such protocols.

Packet re-assembly or re-ordering in multipath transport has the functionality
to equalize the effect of packet scheduling across paths with different
characteristics and restore the original packet order to a certain extent. Obviously,
packet re-assembly is the counterpart of packet scheduling and located at the
far end of the multipath transport. However, packet scheduling schemes exists
which render the re-assembly superfluous or lowering at least its effort.

[comment]: # (MA: It would probably make sense to write such a document on packet re-assembly as well. This becomes crucial for any unreliable MP protocol.)

In this document, we document a series of multipath packet schedulers that
are known to provide performance that matches well the requirements of specific
applications. To describe these packet schedulers, we assume an
abstract transport that is briefly presented in {{abstract}}. We then describe
the different schedulers in {{schedulers}}. To keep the description as simple
and intuitive as possible, we assume here multipath connections that are
composed of two paths, a frequent deployment scenario for multipath transport.
This does not restrict the proposed schedulers to using only two paths.
Implementations are encouraged to support more than 2 paths. We leave the
discussion on how to adapt these abstract schedulers to concrete multipath
transport protocols in future drafts.


# An abstract multipath transport protocol {#abstract}

For simplicity, we assume a multipath transport protocol which can send packets
over different paths. Some protocols such as Multipath TCP {{RFC6824}} support
active and backup paths. We do not assume this in this
document and leave the impact of these active/backup paths in specific
documents.

Furthermore, we assume that there are exactly two active paths for
the presentation of the packet schedulers. We consider that a path is active as
long as it supports the transmission of packets. A Multipath TCP subflow over
which any of the FIN or RST flags were set is not considered as an active path.
Other constraints are possible on whether or not a path is active. These are
specific to the scheduler and vary depending on the goal of the scheduler. An
example of these is that when a path has experienced a certain number N of
retransmission timeouts, the path can be considered inactive.


We assume that the transport protocol maintains one congestion controller per
path as in {{RFC6356}}. We do not assume a specific congestion controller,
but assume that it can be queried by the packet scheduler to verify whether
a packet of length l would be blocked or not by the congestion control scheme.
A window-based congestion controller such as {{RFC6356}} can block a packet
from being transmitted for some time when its congestion window is full. The
same applies to a rate-based congestion controller although the latter could
indicate when the packet could be accepted while the former cannot.

We assume that the multipath transport protocol maintains some state at the
connection level and at the path level. On both level, the multipath
transport protocol will maintain send and receive windows, and a Maximum
Segment Size that is negotiated at connection establishment.

[comment]: # (MA: Linking send and rcv window to a reliable protocol is misleading for MP-QUIC and Datagram or MP-DCCP. Also do not considering path level and linking to connection level only will prevent any path scheduling)


It may also contain some information that is specific to the
application (e.g. total amount of data sent or received) and information about
non-active flows. At the path level, we expect that the multipath transport
protocol will maintain a accurate estimation of the round-trip-time over that
path, possibly a send/receive window, per path MTU information, the state of the
congestion controller, and optionally information that is specific to the
application or the packet scheduler (e.g. priority for one path over another
one).

[comment]: # (To be continued and updated)

# Conventions and Definitions

The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
"SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
"OPTIONAL" in this document are to be interpreted as described in BCP 14
{{RFC2119}}{{RFC8174}} when, and only when, they appear in all capitals,
as shown here.

# Packet scheduling challenges {#challenges}

Packet scheduling tries to balance different quality of service goals with
different constraints of the paths. The balance depends on which of the goals
or constraints is the primary factor for the experience the application is
aiming for. In the following we list these goals and constraints and conclude
by how they can influence each other.

Each path can be subject to a different cost when transmitting data. For example,
a path can introduce a per-byte monetary cost for the transmission (e.g., metered
cellular link). Another cost can be the power consumption when transmitting or
receiving data. These costs are imposing restrictions on when a path can be used
compared to the lower-cost path.

A goal for many applications is to reduce the latency of their transaction. With
multiple paths, each path can have a significantly different latency compared to
the other paths. It is thus crucial to schedule the traffic on a path such that
the latency requirements of the application are satisfied.

Achieving high throughput is another goal of many applications. Streaming applications
often require a minimum bit rate to sustain playback. The scheduler should try to
achieve this bit rate to allow for a flawless streaming experience. Beyond that,
adaptive streaming requires also a more stable throughput experience to ensure
that the bit rate of the video stream is consistent.

Finally, transport protocols impose a receive-window that signals to the sender
how much data the application is willing to receive. When the paths have a large
latency difference, a multipath transport can quickly become receive-window limited.
This limitation comes from the fact that a packet might have been sent on a
high-latency path. If the transport imposes in-order delivery of the data, the
receiver needs to wait to receive this packet over the high-latency path before
providing it to the application. The sender will thus become receive-window limited
and may end up under-utilizing the low-latency path. This can become a major
challenge when trying to achieve high throughput.


All of these quality of service goals and constraints need to be balanced against
each other. A scheduler might decide to trade latency for higher throughput. Or
reduce the throughput with the goal of reducing the cost.


# Packet schedulers {#schedulers}

The packet scheduler is executed every time a packet needs to be transmitted
by the multipath transport protocol. A packet scheduler can consider three
different types of packets:

 - packets that carry new user data
 - packets that carry previously transmitted user data
 - packets that only carry control information (e.g., acknowledgements, address advertisements)

In Multipath TCP, the packet scheduler is only used for packets that carry data. Multipath TCP will typically return acknowledgements on the same path as the one over which data packets were
received. For Multipath QUIC, the situation is different since Multipath QUIC
can acknowledge over one path data that was previously received over another path.
In Multipath TCP, this is only partially possible. The subflow level
acknowledgements must be sent on the subflow where the data was received while
the data-level acknowledgements can be sent over any subflow.

This document uses the Python language to represent multipath schedulers. A
multipath scheduler is represented as a Python function. This function takes the
length of the next packet to schedule as argument and returns the path on which
it will be send. A path is represented as a Python class with the following
attributes:

 - srtt: The smoothed RTT of the path {{RFC6298}}.
 - cc_state: The state of the congestion controller, i.e. either slow_start,
   congestion_avoidance or recovery.
 - blocked(l): A function indicating whether a packet of length l would be
   rejected by the congestion controller.

The schedulers presented can be executed in a simulator {{TODO}} implementing
the abstract multipath protocol presented in {{abstract}}. It can be used to
simulate a file transfer between a client and a server over multiple paths.

## Round-Robin

We use the Round-Robin scheduler as a simple example to illustrate how a packet
scheduler can be specified, but do not recommend its usage. Experiments with
Multipath TCP {{ACMCS14}} indicate that it does not provide good performance.

This packet scheduler uses one additional state at the connection level:
last_path. This stores the identifier of the last path that was used to send a
packet. We assume that the paths are identified by an integer. The scheduler is
defined by the code shown in {{fig-rr}}.


~~~~~~~~~~~~~~~~~~~~~~~~~~~
class RoundRobin(Scheduler):
    """ Chooses an available path in a round-robin manner between two paths. """
    last_path: Optional[Path] = None

    def schedule(self, packet_len: int):
        for p in self.paths:
            if p != self.last_path and not p.blocked(packet_len):
                self.last_path = p
                return p
~~~~~~~~~~~~~~~~~~~~~~~~~~~
{: #fig-rr title="A simple Round Robin scheduler"}

This scheduler does not distinguish between the different types of packets. It
iterates over the available paths and sends over the ones whose congestion
window is open.


## Strict Priority

The Strict Priority scheduler's aim is to select paths based on a priority list.
Some paths might go through networks that are more expensive to use than others.
Then the idea is to select the path with the highest priority if it is available
before looking at others by priority. This scheduler is described by the code
shown in {{fig-strict-prio}}.

~~~~~~~~~~~~~~~~~~~~~~~~~~~
class StrictPriority(Scheduler):
    """ Chooses the first available path in the given order of paths. """

    def schedule(self, packet_len: int):
        for p in self.paths:
            if not p.blocked(packet_len):
                return p
~~~~~~~~~~~~~~~~~~~~~~~~~~~
{: #fig-strict-prio title="A simple Strict Priority scheduler"}

This scheduler can face performance issues if, compared to others, paths with
high priority accept a lot of data but delivered packets with a high latency.
Typically if there are some bufferbloats on the path, the receiver will have to
store packets for a long time in its buffers to ensure an in-order delivery. It
is then recommended to cover these cases in the scheduler implementation with
the help of the congestion control algorithm.

[comment]: # (OB: Path 0 has a higher priority than path one, with congestion window)

## Delay Threshold

The Delay Threshold scheduler selects the first available path with a smoothed
round-trip-time below a certain threshold. The goal is to keep the RTT of the
multipath connection to a small value and avoid having the whole connection
impacted by "bad" pathes. A prototype is shown in {{fig-delay-threshold}}.

~~~~~~~~~~~~~~~~~~~~~~~~~~~
@dataclass
class DelayThreshold(Scheduler):
    """ Chooses the first available path below a certain delay threshold. """
    threshold: float

    def schedule(self, packet_len: int):
        for p in self.paths:
            if p.srtt < self.threshold and not p.blocked(packet_len):
                return p
~~~~~~~~~~~~~~~~~~~~~~~~~~~
{: #fig-delay-threshold title="A simple Delay Threshold scheduler"}

This kind of protection can of course be added to other existing schedulers.

[comment]: # (OB: Path 0 has a higher priority than path one, path one is used if packets has been delayed by more than threshold in transport entity)


## Lowest round-trip-time first


The Lowest round-trip-time first scheduler's goal is to minimize latency for
short flows while at the same time achieving high throughput for long flows {{ACMCS14}}.
To handle the latency differences across the paths when being limited by the
receive-window, this scheduler deploys a fast reinjection mechanism to quickly
recover from the head-of-line blocking.

At each round, the scheduler iterates over the list of paths that are eligible
for transmission. To decide whether or not a path a few conditions need to be
satisfied:

 - The congestion window needs to provide enough space for the segment
 - The path is not in fast-recovery or experiencing retransmission timeouts

Among all the eligible paths, the scheduler will choose the path with the
lowest RTT and transmit the segment with the new data on that path.
{{fig-simple-low-rtt}} illustrates a simple lowest RTT scheduler which does not
include fast reinjections.

~~~~~~~~~~~~~~~~~~~~~~~~~~~
class LowestRTTFirst(Scheduler):
    """ Chooses the first available path with the lowest RTT. """

    def schedule(self, packet_len: int):
        # Sort paths by increasing SRTT
        for p in sorted(self.paths, key=lambda path: path.srtt):
            if not p.blocked(packet_len) \
               and p.cc_state != 'recovery':
                return p
~~~~~~~~~~~~~~~~~~~~~~~~~~~
{: #fig-simple-low-rtt title="A simple Lowest RTT First scheduler"}

To handle head-of-line blocking situations when the paths have a large delay
difference the scheduler uses a strategy of opportunistic retransmission and
path penalization as described in {{NSDI12}.

Opportunistic retransmission kicks in whenever a path is eligible for transmission
but the receive-window advertised by the receiver prevents the sender from transmitting
new data. In that case the sender can transmit previously transmitted data over the
eligible path. To overcome the head-of-line blocking the sender will thus transmit
the packet at the head of the transmission queue over this faster path (if it
hasn't been transmitted on this particular path yet). This packet has thus a
chance to quickly reach the receiver and fill the hole created by the head-of-line
blocking.

Whenever the previously mentioned mechanism kicks in, it is and indication that
the path's round-trip-time is too high to allow the path with the lower RTT to
fully use its capacity. We thus should reduce the transmission rate on this path.
This mechanism is called penalization and is achieved by dividing the congestion
window by 2.

[comment]: # (CP: pseudocode)
[comment]: # (MP: The simulator currently lacks rtx, rcv_wnd and snd_wnd concepts)


## Out-of-order transmission for in-order arrival 

[comment]: # (MA: overload fastest path to match latency of slower path; avoids ideally re-ordering)



~~~~~~~~~~~~~~~~~~~~~~~~~~~

ASCII figure

~~~~~~~~~~~~~~~~~~~~~~~~~~~
{: #fig-ascii title="A simple figure"}

